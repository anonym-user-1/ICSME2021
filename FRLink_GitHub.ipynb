{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries needed\n",
    "import logging\n",
    "import json\n",
    "import nocodeRepoInfo\n",
    "import os\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.matutils import cossim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "REPO_ID = nocodeRepoInfo.REPO_MAP[nocodeRepoInfo.USE_REPO_INDEX]['id']\n",
    "TRAIN_ITERS = 300\n",
    "\n",
    "def getCorpus(df, data_type):\n",
    "    corpus_list = []\n",
    "    df['summary_processed'] = df['summary_processed'].astype(str)\n",
    "    df['description_processed'] = df['description_processed'].astype(str)\n",
    "    df['message_processed'] = df['message_processed'].astype(str)\n",
    "    df['processDiffCode'] = df['processDiffCode'].astype(str)\n",
    "\n",
    "    if data_type == 'text':\n",
    "        for index, row in df.iterrows():\n",
    "            sentence = row['summary_processed'] + row['description_processed'] + row['message_processed']\n",
    "            words = sentence.split(\" \")\n",
    "            sentence_segment = []\n",
    "            for word in words:\n",
    "                if word.strip() != '':\n",
    "                    sentence_segment.append(word.strip())\n",
    "            corpus_list.append(sentence_segment)\n",
    "    else:\n",
    "        for index, row in df.iterrows():\n",
    "            sentence = row['processDiffCode']\n",
    "            words = sentence.split(\" \")\n",
    "            sentence_segment = []\n",
    "            for word in words:\n",
    "                if word.strip() != '':\n",
    "                    sentence_segment.append(word.strip())\n",
    "            corpus_list.append(sentence_segment)\n",
    "            \n",
    "    return corpus_list\n",
    "\n",
    "# create data frame of all project's data\n",
    "df = pd.DataFrame()\n",
    "files = os.listdir('data/')\n",
    "for file in files:\n",
    "    tmp_df = pd.read_parquet('data/'+file)\n",
    "    textual_data = tmp_df.loc[tmp_df['train_flag'] == 1]\n",
    "    df = df.append(textual_data, ignore_index=True)\n",
    "    \n",
    "# creating data set for code and text\n",
    "text_dataset = getCorpus(df, data_type='text')\n",
    "code_dataset = getCorpus(df, data_type='code')\n",
    "code_dct = Dictionary(code_dataset)\n",
    "text_dct = Dictionary(text_dataset)\n",
    "code_corpus = [code_dct.doc2bow(line) for line in code_dataset]  # convert corpus to BoW format\n",
    "text_corpus = [text_dct.doc2bow(line) for line in text_dataset]  # convert corpus to BoW format\n",
    "# create Code mode and Text model\n",
    "code_model = TfidfModel(code_corpus)\n",
    "code_model.save(\"tfidf/models/code_tfidf.model\")\n",
    "text_model = TfidfModel(text_corpus)\n",
    "text_model.save(\"tfidf/models/text_tfidf.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    res = []\n",
    "    filepath = path\n",
    "    logging.info(\"Loaded the file:\"+filepath)\n",
    "    if os.path.isfile(filepath):\n",
    "        file = open(filepath, 'rb')\n",
    "        testlist = json.loads(file.read())\n",
    "        res.extend(testlist)\n",
    "        file.close()\n",
    "    return res\n",
    "\n",
    "\n",
    "def getSim(vec1, vec2):\n",
    "    return cossim(vec1, vec2)\n",
    "\n",
    "\n",
    "def getTextSim(commitText, issueText):\n",
    "    res = 0\n",
    "    for cText in commitText:\n",
    "        cVec = text_model[text_dct.doc2bow([cText])]\n",
    "        for iText in issueText:\n",
    "            iVec = text_model[text_dct.doc2bow([iText])]\n",
    "            res = max(res, getSim(cVec, iVec))\n",
    "    return res\n",
    "\n",
    "\n",
    "def getCodeSim(commitCode, issueCode):\n",
    "    cVec = code_model[code_dct.doc2bow(commitCode)]\n",
    "    iVec = code_model[code_dct.doc2bow(issueCode)]\n",
    "    return getSim(cVec, iVec)\n",
    "\n",
    "\n",
    "def learn(list, ITR):\n",
    "    ThresVal = 0.0\n",
    "    Step = 0.01\n",
    "    LThres = 0.0\n",
    "    F = 0.0\n",
    "    RMax = ITR\n",
    "    while ThresVal <= 1:\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "        for link in list:\n",
    "            if link['val'] >= ThresVal:\n",
    "                if link['type'] == 1:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FP += 1\n",
    "            else:\n",
    "                if link['type'] == 1:\n",
    "                    FN += 1\n",
    "        precision = TP/(TP+FP+1e-8)\n",
    "        recall = TP/(TP+FN+1e-8)\n",
    "        f_measure = (2*precision*recall)/(precision + recall+1e-8)\n",
    "        if recall >= ITR:\n",
    "            if (f_measure > F) or (f_measure == F and recall > RMax):\n",
    "                LThres = ThresVal\n",
    "                RMax = recall\n",
    "                F = f_measure\n",
    "        ThresVal = ThresVal + Step\n",
    "    return LThres\n",
    "\n",
    "\n",
    "def getRes(test_set, t):\n",
    "    size = len(test_set)\n",
    "    right = 0.0\n",
    "    for link in test_set:\n",
    "        if link['type'] == 1 and link['val'] >= t:\n",
    "            right += 1\n",
    "        elif link['type'] == 0 and link['val'] < t:\n",
    "            right += 1\n",
    "    return right/size\n",
    "\n",
    "\n",
    "def evaluation(test_set, t):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for link in test_set:\n",
    "        if link['val'] >= t:\n",
    "            if link['type'] == 1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        else:\n",
    "            if link['type'] == 1:\n",
    "                FN += 1\n",
    "    precision = float(TP) / (TP + FP+1e-8)\n",
    "    recall = float(TP) / (TP + FN+1e-8)\n",
    "    f_measure = (2 * precision * recall) / (precision + recall+1e-8)\n",
    "    logging.info(\"precision:%f  recall:%f  f_measure:%f\" % (precision, recall, f_measure))\n",
    "\n",
    "    \n",
    "def build():\n",
    "    filelist = os.listdir('data/')\n",
    "    for i in range(0, len(filelist)):\n",
    "        filepath = os.path.join('data/', filelist[i])\n",
    "        logging.info(\"Loaded the file:\" + filepath)\n",
    "        if os.path.isfile(filepath):\n",
    "            df1 = pd.read_parquet(filepath)\n",
    "            df1 = df1.loc[df1['train_flag'] == 1]\n",
    "\n",
    "            df1['summary_processed'] = df1['summary_processed'].astype(str)\n",
    "            df1['description_processed'] = df1['description_processed'].astype(str)\n",
    "            df1['message_processed'] = df1['message_processed'].astype(str)\n",
    "            df1['processDiffCode'] = df1['processDiffCode'].astype(str)\n",
    "    \n",
    "            link_list = []\n",
    "            for index, row in df1.iterrows():\n",
    "                type = row['label'] \n",
    "                val = max(getTextSim((row['summary_processed']+row['description_processed']).split(\" \"), row['message_processed'].split(\" \")),\n",
    "                          getCodeSim(row['description_processed'].split(\" \"), row['processDiffCode'].split(\" \"))) \n",
    "                link_list.append({'type': type, 'val': val})\n",
    "            res = json.dumps(link_list, indent=4)\n",
    "            trainSet = open('train/'+filelist[i].split('.')[0]+'.dat', \"w\")\n",
    "            trainSet.write(res)\n",
    "            trainSet.close()\n",
    "            \n",
    "def build_test():\n",
    "    filelist = os.listdir('data/')\n",
    "    for i in range(0, len(filelist)):\n",
    "        filepath = os.path.join('data/', filelist[i])\n",
    "        logging.info(\"Loaded the file:\" + filepath)\n",
    "        if os.path.isfile(filepath):\n",
    "            df1 = pd.read_parquet(filepath)\n",
    "            df1 = df1.loc[df1['train_flag'] == 0]\n",
    "\n",
    "            df1['summary_processed'] = df1['summary_processed'].astype(str)\n",
    "            df1['description_processed'] = df1['description_processed'].astype(str)\n",
    "            df1['message_processed'] = df1['message_processed'].astype(str)\n",
    "            df1['processDiffCode'] = df1['processDiffCode'].astype(str)\n",
    "    \n",
    "            link_list = []\n",
    "            for index, row in df1.iterrows():\n",
    "                type = row['label'] \n",
    "                val = max(getTextSim((row['summary_processed']+row['description_processed']).split(\" \"), row['message_processed'].split(\" \")),\n",
    "                          getCodeSim(row['description_processed'].split(\" \"), row['processDiffCode'].split(\" \"))) \n",
    "                link_list.append({'type': type, 'val': val})\n",
    "            res = json.dumps(link_list, indent=4)\n",
    "            trainSet = open('test/'+filelist[i].split('.')[0]+'.dat', \"w\")\n",
    "            trainSet.write(res)\n",
    "            trainSet.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    build()\n",
    "    build_test()\n",
    "    files = os.listdir('train/')\n",
    "    for file in files:\n",
    "        trainset = read_data(path='train/'+file)\n",
    "        testset = read_data(path='test/'+file)\n",
    "        t = learn(trainset, 0.88)\n",
    "        res = getRes(testset, t)\n",
    "        logging.info(t)\n",
    "        logging.info(res)\n",
    "        evaluation(testset, t)\n",
    "        logging.info(\"Finished!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
